{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"02-BERT.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f06e03bbb11a4b83abd69974f22263a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d1fc90d2c03b46e3acccc5075c92cd52","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a5ef729f3d0144bca4d4c09480de9b59","IPY_MODEL_ef9082a065fe44f3a7b54043dc6c892b"]}},"d1fc90d2c03b46e3acccc5075c92cd52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5ef729f3d0144bca4d4c09480de9b59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_29aeec574f7942de850b082af664fd2c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ed93e42c896422eb3a81461d6181d36"}},"ef9082a065fe44f3a7b54043dc6c892b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e65314a966f742bc85812d238bf1869b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:00&lt;00:00, 6.22MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3df58c4fbde1406cbdb25f5cfafc397a"}},"29aeec574f7942de850b082af664fd2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2ed93e42c896422eb3a81461d6181d36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e65314a966f742bc85812d238bf1869b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3df58c4fbde1406cbdb25f5cfafc397a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1228988c5d1c4974b3721d90f3861918":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_404e989c69594970a32b2ad8eef03d52","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b4ca1ca5d5754d3b89597a62093a31b1","IPY_MODEL_c0653fe24c2b45a299d1797722033d2f"]}},"404e989c69594970a32b2ad8eef03d52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4ca1ca5d5754d3b89597a62093a31b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_14c5e70ac34440fca4de438e4e4bc10b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a565954ab6ab4591af15d263560aec45"}},"c0653fe24c2b45a299d1797722033d2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e7e6355abb4b48c1b88384f9e1beb41c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 936B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a2e35da4437947e89f6f2eee7b496e16"}},"14c5e70ac34440fca4de438e4e4bc10b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a565954ab6ab4591af15d263560aec45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7e6355abb4b48c1b88384f9e1beb41c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a2e35da4437947e89f6f2eee7b496e16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75f32edbca2c48788c69b836c64c2353":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_baecc12715c9414ebe671c7501423c9e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_966c1f3188a444f68a38a36d6b58a8ac","IPY_MODEL_97d8787e089740ff85046c16ad2acde3"]}},"baecc12715c9414ebe671c7501423c9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"966c1f3188a444f68a38a36d6b58a8ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_aa8de1a4e5eb4ef7a742a52f7b51f5b7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e9d94a976618483ebf26f24fff391fb5"}},"97d8787e089740ff85046c16ad2acde3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_57c5ba793fb74b8e9fdceb31bf158842","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [00:24&lt;00:00, 29.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8fb73c16a2fc4649b05102a63b148df0"}},"aa8de1a4e5eb4ef7a742a52f7b51f5b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e9d94a976618483ebf26f24fff391fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57c5ba793fb74b8e9fdceb31bf158842":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8fb73c16a2fc4649b05102a63b148df0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"P58qy4--s5_x"},"source":["# **네이버 영화리뷰 감정분석 with BERT**\n","\n","BERT(Bidirectional Encoder Representations from Transformers)는 구글이 개발한 사전훈련(pre-training) 모델입니다. 위키피디아 같은 텍스트 코퍼스를 사용해서 미리 학습을 하면, 언어의 기본적인 패턴을 이해한 모델이 만들어집니다. 이를 기반으로 새로운 문제에 적용하는 전이학습(transfer learning)을 수행합니다. 좀 더 적은 데이터로 보다 빠르게 학습이 가능하다는 장점이 있습니다. 그래서 최근 자연어처리의 핵심 기법으로 떠오르고 있습니다.\n","\n","이 예제에서는 한글 NLP의 Hello world라고 할 수 있는 네이버 영화리뷰 감정분석을 구현해보겠습니다. 가장 유명한 모델 중 하나인 Hugging Face의 PyTorch BERT를 사용하였습니다. 아래의 Chris McCormick의 블로그를 참조하여 한글에 맞게 수정하였음을 미리 알려드립니다.\n","\n","< BERT Fine-Tuning Tutorial with PyTorch ><br>\n","-> https://mccormickml.com/2019/07/22/BERT-fine-tuning\n","<br>\n","\n","BERT에 대해서 좀 더 자세한 설명은 박상길님과 Jay Alammar의 블로그를 참조하시기 바랍니다.\n","\n","< BERT 톺아보기 ><br>\n","-> http://docs.likejazz.com/bert/\n","\n","< The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) ><br>\n","-> http://jalammar.github.io/illustrated-bert/\n","<br>\n","<br>\n","\n","아래 사이트를 참고하여 만들었습니다. <br>\n","-> https://colab.research.google.com/drive/1tIf0Ugdqg4qT7gcxia3tL7und64Rv1dP"]},{"cell_type":"markdown","metadata":{"id":"i45d7E0L8bZ_"},"source":["\n","\n","# **준비 사항**"]},{"cell_type":"code","metadata":{"id":"WkAHQrj2Vjbl","executionInfo":{"status":"ok","timestamp":1603944048822,"user_tz":-540,"elapsed":74942,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"8c53b4ff-dc10-49fb-9310-dad6ad875ca0","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Hugging Face의 트랜스포머 모델을 설치\n","!pip install transformers\n","!pip install keras\n","!pip install pandas\n","!pip install sklearn\n","!pip install tensorflow --upgrade"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 11.8MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 53.5MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting tokenizers==0.9.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 51.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 39.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=e05fd51bd8bde964f45af0c8014ed77f8460978db519e5ad6bf478e26c586d53\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n","Collecting tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/ad/769c195c72ac72040635c66cd9ba7b0f4b4fc1ac67e59b99fa6988446c22/tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n","\u001b[K     |████████████████████████████████| 320.4MB 49kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n","Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.1)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n","Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n","Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n","Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.0)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.2)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n","Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n","Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n","Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n","Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.3.1)\n","Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n","Installing collected packages: tensorflow\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","Successfully installed tensorflow-2.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o1TifTYU9fYx","executionInfo":{"status":"ok","timestamp":1603944053112,"user_tz":-540,"elapsed":79219,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"be0e2719-012a-4663-b5a0-d8885803b034","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip list"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Package                       Version        \n","----------------------------- ---------------\n","absl-py                       0.10.0         \n","alabaster                     0.7.12         \n","albumentations                0.1.12         \n","altair                        4.1.0          \n","argon2-cffi                   20.1.0         \n","asgiref                       3.2.10         \n","astor                         0.8.1          \n","astropy                       4.1            \n","astunparse                    1.6.3          \n","async-generator               1.10           \n","atari-py                      0.2.6          \n","atomicwrites                  1.4.0          \n","attrs                         20.2.0         \n","audioread                     2.1.9          \n","autograd                      1.3            \n","Babel                         2.8.0          \n","backcall                      0.2.0          \n","beautifulsoup4                4.6.3          \n","bleach                        3.2.1          \n","blis                          0.4.1          \n","bokeh                         2.1.1          \n","Bottleneck                    1.3.2          \n","branca                        0.4.1          \n","bs4                           0.0.1          \n","CacheControl                  0.12.6         \n","cachetools                    4.1.1          \n","catalogue                     1.0.0          \n","certifi                       2020.6.20      \n","cffi                          1.14.3         \n","chainer                       7.4.0          \n","chardet                       3.0.4          \n","click                         7.1.2          \n","cloudpickle                   1.3.0          \n","cmake                         3.12.0         \n","cmdstanpy                     0.9.5          \n","colorlover                    0.3.0          \n","community                     1.0.0b1        \n","contextlib2                   0.5.5          \n","convertdate                   2.2.2          \n","coverage                      3.7.1          \n","coveralls                     0.5            \n","crcmod                        1.7            \n","cufflinks                     0.17.3         \n","cupy-cuda101                  7.4.0          \n","cvxopt                        1.2.5          \n","cvxpy                         1.0.31         \n","cycler                        0.10.0         \n","cymem                         2.0.3          \n","Cython                        0.29.21        \n","daft                          0.0.4          \n","dask                          2.12.0         \n","dataclasses                   0.7            \n","datascience                   0.10.6         \n","debugpy                       1.0.0          \n","decorator                     4.4.2          \n","defusedxml                    0.6.0          \n","descartes                     1.1.0          \n","dill                          0.3.2          \n","distributed                   1.25.3         \n","Django                        3.1.2          \n","dlib                          19.18.0        \n","dm-tree                       0.1.5          \n","docopt                        0.6.2          \n","docutils                      0.16           \n","dopamine-rl                   1.0.5          \n","earthengine-api               0.1.238        \n","easydict                      1.9            \n","ecos                          2.0.7.post1    \n","editdistance                  0.5.3          \n","en-core-web-sm                2.2.5          \n","entrypoints                   0.3            \n","ephem                         3.7.7.1        \n","et-xmlfile                    1.0.1          \n","fa2                           0.3.5          \n","fancyimpute                   0.4.3          \n","fastai                        1.0.61         \n","fastdtw                       0.3.4          \n","fastprogress                  1.0.0          \n","fastrlock                     0.5            \n","fbprophet                     0.7.1          \n","feather-format                0.4.1          \n","filelock                      3.0.12         \n","firebase-admin                4.4.0          \n","fix-yahoo-finance             0.0.22         \n","Flask                         1.1.2          \n","folium                        0.8.3          \n","future                        0.16.0         \n","gast                          0.3.3          \n","GDAL                          2.2.2          \n","gdown                         3.6.4          \n","gensim                        3.6.0          \n","geographiclib                 1.50           \n","geopy                         1.17.0         \n","gin-config                    0.3.0          \n","glob2                         0.7            \n","google                        2.0.3          \n","google-api-core               1.16.0         \n","google-api-python-client      1.7.12         \n","google-auth                   1.17.2         \n","google-auth-httplib2          0.0.4          \n","google-auth-oauthlib          0.4.1          \n","google-cloud-bigquery         1.21.0         \n","google-cloud-bigquery-storage 1.1.0          \n","google-cloud-core             1.0.3          \n","google-cloud-datastore        1.8.0          \n","google-cloud-firestore        1.7.0          \n","google-cloud-language         1.2.0          \n","google-cloud-storage          1.18.1         \n","google-cloud-translate        1.5.0          \n","google-colab                  1.0.0          \n","google-pasta                  0.2.0          \n","google-resumable-media        0.4.1          \n","googleapis-common-protos      1.52.0         \n","googledrivedownloader         0.4            \n","graphviz                      0.10.1         \n","grpcio                        1.33.1         \n","gspread                       3.0.1          \n","gspread-dataframe             3.0.8          \n","gym                           0.17.3         \n","h5py                          2.10.0         \n","HeapDict                      1.0.1          \n","holidays                      0.10.3         \n","holoviews                     1.13.4         \n","html5lib                      1.0.1          \n","httpimport                    0.5.18         \n","httplib2                      0.17.4         \n","httplib2shim                  0.0.3          \n","humanize                      0.5.1          \n","hyperopt                      0.1.2          \n","ideep4py                      2.0.0.post3    \n","idna                          2.10           \n","image                         1.5.32         \n","imageio                       2.4.1          \n","imagesize                     1.2.0          \n","imbalanced-learn              0.4.3          \n","imblearn                      0.0            \n","imgaug                        0.2.9          \n","importlib-metadata            2.0.0          \n","importlib-resources           3.1.0          \n","imutils                       0.5.3          \n","inflect                       2.1.0          \n","iniconfig                     1.1.1          \n","intel-openmp                  2020.0.133     \n","intervaltree                  2.1.0          \n","ipykernel                     4.10.1         \n","ipython                       5.5.0          \n","ipython-genutils              0.2.0          \n","ipython-sql                   0.3.9          \n","ipywidgets                    7.5.1          \n","itsdangerous                  1.1.0          \n","jax                           0.2.4          \n","jaxlib                        0.1.56+cuda101 \n","jdcal                         1.4.1          \n","jedi                          0.17.2         \n","jieba                         0.42.1         \n","Jinja2                        2.11.2         \n","joblib                        0.17.0         \n","jpeg4py                       0.1.4          \n","jsonschema                    2.6.0          \n","jupyter                       1.0.0          \n","jupyter-client                5.3.5          \n","jupyter-console               5.2.0          \n","jupyter-core                  4.6.3          \n","jupyterlab-pygments           0.1.2          \n","kaggle                        1.5.9          \n","kapre                         0.1.3.1        \n","Keras                         2.4.3          \n","Keras-Preprocessing           1.1.2          \n","keras-vis                     0.4.1          \n","kiwisolver                    1.2.0          \n","knnimpute                     0.1.0          \n","korean-lunar-calendar         0.2.1          \n","librosa                       0.6.3          \n","lightgbm                      2.2.3          \n","llvmlite                      0.31.0         \n","lmdb                          0.99           \n","lucid                         0.3.8          \n","LunarCalendar                 0.0.9          \n","lxml                          4.2.6          \n","Markdown                      3.3.2          \n","MarkupSafe                    1.1.1          \n","matplotlib                    3.2.2          \n","matplotlib-venn               0.11.5         \n","missingno                     0.4.2          \n","mistune                       0.8.4          \n","mizani                        0.6.0          \n","mkl                           2019.0         \n","mlxtend                       0.14.0         \n","more-itertools                8.5.0          \n","moviepy                       0.2.3.5        \n","mpmath                        1.1.0          \n","msgpack                       1.0.0          \n","multiprocess                  0.70.10        \n","multitasking                  0.0.9          \n","murmurhash                    1.0.2          \n","music21                       5.5.0          \n","natsort                       5.5.0          \n","nbclient                      0.5.1          \n","nbconvert                     5.6.1          \n","nbformat                      5.0.8          \n","nest-asyncio                  1.4.1          \n","networkx                      2.5            \n","nibabel                       3.0.2          \n","nltk                          3.2.5          \n","notebook                      5.3.1          \n","np-utils                      0.5.12.1       \n","numba                         0.48.0         \n","numexpr                       2.7.1          \n","numpy                         1.18.5         \n","nvidia-ml-py3                 7.352.0        \n","oauth2client                  4.1.3          \n","oauthlib                      3.1.0          \n","okgrade                       0.4.3          \n","opencv-contrib-python         4.1.2.30       \n","opencv-python                 4.1.2.30       \n","openpyxl                      2.5.9          \n","opt-einsum                    3.3.0          \n","osqp                          0.6.1          \n","packaging                     20.4           \n","palettable                    3.3.0          \n","pandas                        1.1.3          \n","pandas-datareader             0.9.0          \n","pandas-gbq                    0.13.3         \n","pandas-profiling              1.4.1          \n","pandocfilters                 1.4.2          \n","panel                         0.9.7          \n","param                         1.9.3          \n","parso                         0.7.1          \n","pathlib                       1.0.1          \n","patsy                         0.5.1          \n","pexpect                       4.8.0          \n","pickleshare                   0.7.5          \n","Pillow                        7.0.0          \n","pip                           19.3.1         \n","pip-tools                     4.5.1          \n","plac                          1.1.3          \n","plotly                        4.4.1          \n","plotnine                      0.6.0          \n","pluggy                        0.7.1          \n","portpicker                    1.3.1          \n","prefetch-generator            1.0.1          \n","preshed                       3.0.2          \n","prettytable                   1.0.1          \n","progressbar2                  3.38.0         \n","prometheus-client             0.8.0          \n","promise                       2.3            \n","prompt-toolkit                1.0.18         \n","protobuf                      3.12.4         \n","psutil                        5.4.8          \n","psycopg2                      2.7.6.1        \n","ptyprocess                    0.6.0          \n","py                            1.9.0          \n","pyarrow                       0.14.1         \n","pyasn1                        0.4.8          \n","pyasn1-modules                0.2.8          \n","pycocotools                   2.0.2          \n","pycparser                     2.20           \n","pyct                          0.4.8          \n","pydata-google-auth            1.1.0          \n","pydot                         1.3.0          \n","pydot-ng                      2.0.0          \n","pydotplus                     2.0.2          \n","PyDrive                       1.3.1          \n","pyemd                         0.5.1          \n","pyglet                        1.5.0          \n","Pygments                      2.6.1          \n","pygobject                     3.26.1         \n","pymc3                         3.7            \n","PyMeeus                       0.3.7          \n","pymongo                       3.11.0         \n","pymystem3                     0.2.0          \n","PyOpenGL                      3.1.5          \n","pyparsing                     2.4.7          \n","pyrsistent                    0.17.3         \n","pysndfile                     1.3.8          \n","PySocks                       1.7.1          \n","pystan                        2.19.1.1       \n","pytest                        3.6.4          \n","python-apt                    1.6.5+ubuntu0.3\n","python-chess                  0.23.11        \n","python-dateutil               2.8.1          \n","python-louvain                0.14           \n","python-slugify                4.0.1          \n","python-utils                  2.4.0          \n","pytz                          2018.9         \n","pyviz-comms                   0.7.6          \n","PyWavelets                    1.1.1          \n","PyYAML                        3.13           \n","pyzmq                         19.0.2         \n","qtconsole                     4.7.7          \n","QtPy                          1.9.0          \n","regex                         2019.12.20     \n","requests                      2.23.0         \n","requests-oauthlib             1.3.0          \n","resampy                       0.2.2          \n","retrying                      1.3.3          \n","rpy2                          3.2.7          \n","rsa                           4.6            \n","sacremoses                    0.0.43         \n","scikit-image                  0.16.2         \n","scikit-learn                  0.22.2.post1   \n","scipy                         1.4.1          \n","screen-resolution-extra       0.0.0          \n","scs                           2.1.2          \n","seaborn                       0.11.0         \n","Send2Trash                    1.5.0          \n","sentencepiece                 0.1.94         \n","setuptools                    50.3.0         \n","setuptools-git                1.2            \n","Shapely                       1.7.1          \n","simplegeneric                 0.8.1          \n","six                           1.15.0         \n","sklearn                       0.0            \n","sklearn-pandas                1.8.0          \n","slugify                       0.0.1          \n","smart-open                    3.0.0          \n","snowballstemmer               2.0.0          \n","sortedcontainers              2.2.2          \n","spacy                         2.2.4          \n","Sphinx                        1.8.5          \n","sphinxcontrib-serializinghtml 1.1.4          \n","sphinxcontrib-websupport      1.2.4          \n","SQLAlchemy                    1.3.20         \n","sqlparse                      0.4.1          \n","srsly                         1.0.2          \n","statsmodels                   0.10.2         \n","sympy                         1.1.1          \n","tables                        3.4.4          \n","tabulate                      0.8.7          \n","tblib                         1.7.0          \n","tensorboard                   2.3.0          \n","tensorboard-plugin-wit        1.7.0          \n","tensorboardcolab              0.0.22         \n","tensorflow                    2.3.1          \n","tensorflow-addons             0.8.3          \n","tensorflow-datasets           4.0.1          \n","tensorflow-estimator          2.3.0          \n","tensorflow-gcs-config         2.3.0          \n","tensorflow-hub                0.9.0          \n","tensorflow-metadata           0.24.0         \n","tensorflow-privacy            0.2.2          \n","tensorflow-probability        0.11.0         \n","termcolor                     1.1.0          \n","terminado                     0.9.1          \n","testpath                      0.4.4          \n","text-unidecode                1.3            \n","textblob                      0.15.3         \n","textgenrnn                    1.4.1          \n","Theano                        1.0.5          \n","thinc                         7.4.0          \n","tifffile                      2020.9.3       \n","tokenizers                    0.9.2          \n","toml                          0.10.1         \n","toolz                         0.11.1         \n","torch                         1.6.0+cu101    \n","torchsummary                  1.5.1          \n","torchtext                     0.3.1          \n","torchvision                   0.7.0+cu101    \n","tornado                       5.1.1          \n","tqdm                          4.41.1         \n","traitlets                     4.3.3          \n","transformers                  3.4.0          \n","tweepy                        3.6.0          \n","typeguard                     2.7.1          \n","typing-extensions             3.7.4.3        \n","tzlocal                       1.5.1          \n","umap-learn                    0.4.6          \n","uritemplate                   3.0.1          \n","urllib3                       1.24.3         \n","vega-datasets                 0.8.0          \n","wasabi                        0.8.0          \n","wcwidth                       0.2.5          \n","webencodings                  0.5.1          \n","Werkzeug                      1.0.1          \n","wheel                         0.35.1         \n","widgetsnbextension            3.5.1          \n","wordcloud                     1.5.0          \n","wrapt                         1.12.1         \n","xarray                        0.15.1         \n","xgboost                       0.90           \n","xkit                          0.0.0          \n","xlrd                          1.1.0          \n","xlwt                          1.3.0          \n","yellowbrick                   0.9.1          \n","zict                          2.0.0          \n","zipp                          3.3.1          \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"75dIz2fNWG8F","executionInfo":{"status":"ok","timestamp":1603944058611,"user_tz":-540,"elapsed":84715,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["import tensorflow as tf\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RNWLrmTw_9Mr"},"source":["박은정님의 네이버 영화리뷰 감정분석 데이터를 Github에서 다운로드 합니다. 아래와 같이 nsmc 디렉토리에 있는 ratings_train.txt와 ratings_test.txt를 사용하겠습니다. \n","<br>"]},{"cell_type":"markdown","metadata":{"id":"h_U3uMySBCIV"},"source":["<br>\n","\n","# **데이터 로드**"]},{"cell_type":"code","metadata":{"id":"OKSgTcfrG_fe","executionInfo":{"status":"ok","timestamp":1603944134189,"user_tz":-540,"elapsed":160285,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"f97c50a4-a9d4-4b0f-8245-086447522c2a","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0LPEdb2tWfIU","executionInfo":{"status":"ok","timestamp":1603944135633,"user_tz":-540,"elapsed":161721,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"ed9d02b4-b838-40a6-f86b-349cb6832dd9","colab":{"base_uri":"https://localhost:8080/"}},"source":["path = '/content/drive/My Drive/Colab Notebooks/2020-PoscoICT/Data/'\n","# 판다스로 훈련셋과 테스트셋 데이터 로드\n","train = pd.read_csv(path+\"nsmc/ratings_train.txt\", sep='\\t')\n","test = pd.read_csv(path+\"nsmc/ratings_test.txt\", sep='\\t')\n","\n","print(train.shape)\n","print(test.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(150000, 3)\n","(50000, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8Cl0j7TZBoeL"},"source":["훈련셋 150,000개와 테스트셋 50,000개의 데이터가 존재합니다.\n","<br>"]},{"cell_type":"code","metadata":{"id":"tejY9ZhABYWl","executionInfo":{"status":"ok","timestamp":1603944135634,"user_tz":-540,"elapsed":161713,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"f6d755c1-b99b-4826-b045-7e76e81607ed","colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["# 훈련셋의 앞부분 출력\n","train.head(10)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5403919</td>\n","      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7797314</td>\n","      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>9443947</td>\n","      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7156791</td>\n","      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5912145</td>\n","      <td>왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n","5   5403919      막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.      0\n","6   7797314                              원작의 긴장감을 제대로 살려내지못했다.      0\n","7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...      0\n","8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n","9   5912145      왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?      1"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"hZ12coTLB7H3"},"source":["id는 회원정보, document는 리뷰 문장입니다. label이 0이면 부정, 1이면 긍정으로 분류됩니다. id는 사용하지 않기 때문에 document와 label만 추출하겠습니다. "]},{"cell_type":"markdown","metadata":{"id":"XgjMzosCDD35"},"source":["<br>\n","\n","# **전처리 - 훈련셋**"]},{"cell_type":"code","metadata":{"id":"2GoESQ0jbybJ"},"source":["# 리뷰 문장 추출\n","sentences = train['document']\n","sentences[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8KkJZvhccRUJ","executionInfo":{"status":"ok","timestamp":1603944135637,"user_tz":-540,"elapsed":161699,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"f65db462-e475-4e6e-d073-49d20132a342","colab":{"base_uri":"https://localhost:8080/"}},"source":["# BERT의 입력 형식에 맞게 변환\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","sentences[:10]"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP]',\n"," '[CLS] 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나 [SEP]',\n"," '[CLS] 너무재밓었다그래서보는것을추천한다 [SEP]',\n"," '[CLS] 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정 [SEP]',\n"," '[CLS] 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다 [SEP]',\n"," '[CLS] 막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움. [SEP]',\n"," '[CLS] 원작의 긴장감을 제대로 살려내지못했다. [SEP]',\n"," '[CLS] 별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네 [SEP]',\n"," '[CLS] 액션이 없는데도 재미 있는 몇안되는 영화 [SEP]',\n"," '[CLS] 왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나? [SEP]']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"NeXrqpRaBjOX"},"source":["![대체 텍스트](https://mino-park7.github.io/images/2019/02/bert-input-representation.png)\n","\n","BERT의 입력은 위의 그림과 같은 형식입니다. Classification을 뜻하는 [CLS] 심볼이 제일 앞에 삽입됩니다. 파인튜닝시 출력에서 이 위치의 값을 사용하여 분류를 합니다. [SEP]은 Seperation을 가리키는데, 두 문장를 구분하는 역할을 합니다. 이 예제에서는 문장이 하나이므로 [SEP]도 하나만 넣습니다.\n","<br>\n","<br>"]},{"cell_type":"code","metadata":{"id":"7hBblIVQcXJR","executionInfo":{"status":"ok","timestamp":1603944135638,"user_tz":-540,"elapsed":161692,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"f6d93282-9fd9-4554-a1a7-03829d30f1ce","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 라벨 추출\n","labels = train['label'].values\n","labels"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, ..., 0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"PwEplfDvcnZG","executionInfo":{"status":"ok","timestamp":1603944159784,"user_tz":-540,"elapsed":185829,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"91bb9837-0037-40eb-9a9e-808f05d0c164","colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["f06e03bbb11a4b83abd69974f22263a0","d1fc90d2c03b46e3acccc5075c92cd52","a5ef729f3d0144bca4d4c09480de9b59","ef9082a065fe44f3a7b54043dc6c892b","29aeec574f7942de850b082af664fd2c","2ed93e42c896422eb3a81461d6181d36","e65314a966f742bc85812d238bf1869b","3df58c4fbde1406cbdb25f5cfafc397a"]}},"source":["# BERT의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","print (sentences[0])\n","print (tokenized_texts[0])"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f06e03bbb11a4b83abd69974f22263a0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","[CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP]\n","['[CLS]', '아', '더', '##빙', '.', '.', '진', '##짜', '짜', '##증', '##나', '##네', '##요', '목', '##소', '##리', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gV6SRXmlTMjr"},"source":["BERT는 형태소분석으로 토큰을 분리하지 않습니다. **WordPiece**라는 통계적인 방식을 사용합니다. 한 단어내에서 자주 나오는 글자들을 붙여서 하나의 토큰으로 만듭니다. 이렇게 하면 언어에 상관없이 토큰을 생성할 수 있다는 장점이 있습니다. 또한 신조어 같이 사전에 없는 단어를 처리하기도 좋습니다. \n","\n","위의 결과에서 ## 기호는 앞 토큰과 이어진다는 표시입니다. 토크나이저는 여러 언어의 데이터를 기반으로 만든 'bert-base-multilingual-cased'를 사용합니다. 그래서 한글도 처리가 가능합니다.\n","<br>"]},{"cell_type":"code","metadata":{"id":"VJ76KiP_dLn-","executionInfo":{"status":"ok","timestamp":1603944164309,"user_tz":-540,"elapsed":190346,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"e2396521-d313-4418-d001-177db7fda678","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 128\n","\n","# 토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   101,   9519,   9074, 119005,    119,    119,   9708, 119235,\n","         9715, 119230,  16439,  77884,  48549,   9284,  22333,  12692,\n","          102,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"kHI53Jt8VrY8"},"source":["보통 딥러닝 모델에는 토큰 자체를 입력으로 넣을 수 없습니다. 임베딩 레이어에는 토큰을 숫자로 된 인덱스로 변환하여 사용합니다. BERT의 토크나이저는 {단어토큰:인덱스}로 구성된 단어사전을 가지고 있습니다. 이를 참조하여 토큰을 인덱스로 바꿔줍니다.\n","<br>"]},{"cell_type":"code","metadata":{"id":"pKfL8SotdVaW","executionInfo":{"status":"ok","timestamp":1603944175133,"user_tz":-540,"elapsed":201161,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"985e09fa-672a-432e-f583-f857a9447ce7","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 어텐션 마스크 초기화\n","attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1f5Vq3-7eNKH","executionInfo":{"status":"ok","timestamp":1603944176239,"user_tz":-540,"elapsed":202265,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 훈련셋과 검증셋으로 분리\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n","                                                                                    labels, \n","                                                                                    random_state=2018, \n","                                                                                    test_size=0.1)\n","\n","# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n","                                                       input_ids,\n","                                                       random_state=2018, \n","                                                       test_size=0.1)\n","\n","# 데이터를 파이토치의 텐서로 변환\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\n","\n","# print(train_inputs[0])\n","# print(train_labels[0])\n","# print(train_masks[0])\n","# print(validation_inputs[0])\n","# print(validation_labels[0])\n","# print(validation_masks[0])"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3vlyUJuVRo5","executionInfo":{"status":"ok","timestamp":1603944176241,"user_tz":-540,"elapsed":202264,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 배치 사이즈\n","batch_size = 32\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zkqUHx51dffp"},"source":["<br>\n","<br>\n","\n","# **전처리 - 테스트셋**"]},{"cell_type":"code","metadata":{"id":"xgrsNuArd4pj","executionInfo":{"status":"ok","timestamp":1603944176242,"user_tz":-540,"elapsed":202263,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 리뷰 문장 추출\n","sentences = test['document']\n","# sentences[:10]"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gtz3QZt9d4pz","executionInfo":{"status":"ok","timestamp":1603944176242,"user_tz":-540,"elapsed":202259,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# BERT의 입력 형식에 맞게 변환\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","# sentences[:10]"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"li8oRajbd4p3","executionInfo":{"status":"ok","timestamp":1603944176243,"user_tz":-540,"elapsed":202258,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 라벨 추출\n","labels = test['label'].values\n","# labels"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"lvpQ49nEd4p6","executionInfo":{"status":"ok","timestamp":1603944184761,"user_tz":-540,"elapsed":210768,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"45f1ef15-20b6-414a-80af-4870a39f9166","colab":{"base_uri":"https://localhost:8080/"}},"source":["# BERT의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","print (sentences[0])\n","print (tokenized_texts[0])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[CLS] 굳 ㅋ [SEP]\n","['[CLS]', '굳', '[UNK]', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HI9viuAvd4p_","executionInfo":{"status":"ok","timestamp":1603944186871,"user_tz":-540,"elapsed":212868,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"ab7c693c-e7d1-4bf4-aeb6-dc3c260fb211","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 128\n","\n","# 토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 101, 8911,  100,  102,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"v1NKmP0Fd4qD","executionInfo":{"status":"ok","timestamp":1603944190286,"user_tz":-540,"elapsed":216281,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 어텐션 마스크 초기화\n","attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","# print(attention_masks[0])"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIkaYCGbd4qG","executionInfo":{"status":"ok","timestamp":1603944191411,"user_tz":-540,"elapsed":217403,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 데이터를 파이토치의 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","test_labels = torch.tensor(labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","# print(test_inputs[0])\n","# print(test_labels[0])\n","# print(test_masks[0])"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"7gwdYv1Ad4qK","executionInfo":{"status":"ok","timestamp":1603944191412,"user_tz":-540,"elapsed":217402,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 배치 사이즈\n","batch_size = 32\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FBvpU-Hfgcth"},"source":["<br>\n","\n","# **모델 생성**\n","\n","- GPU가 없는 노트북에서 테스트하기 때문에 아래부분은 생략한다.\n","- GPU가 있을 경우 아래 코드 활용 가능"]},{"cell_type":"code","metadata":{"id":"f6enIxvt1FB2","executionInfo":{"status":"ok","timestamp":1603944191412,"user_tz":-540,"elapsed":217391,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"b83cdf50-d3b0-4071-8de9-0ad0d6d89014","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 디바이스 설정\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')\n","\n","print(device)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n","cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MS2MXSiLg5zC","executionInfo":{"status":"ok","timestamp":1603944215579,"user_tz":-540,"elapsed":241549,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"15c1fd14-103b-4187-e6ba-3dd612e933a9","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1228988c5d1c4974b3721d90f3861918","404e989c69594970a32b2ad8eef03d52","b4ca1ca5d5754d3b89597a62093a31b1","c0653fe24c2b45a299d1797722033d2f","14c5e70ac34440fca4de438e4e4bc10b","a565954ab6ab4591af15d263560aec45","e7e6355abb4b48c1b88384f9e1beb41c","a2e35da4437947e89f6f2eee7b496e16","75f32edbca2c48788c69b836c64c2353","baecc12715c9414ebe671c7501423c9e","966c1f3188a444f68a38a36d6b58a8ac","97d8787e089740ff85046c16ad2acde3","aa8de1a4e5eb4ef7a742a52f7b51f5b7","e9d94a976618483ebf26f24fff391fb5","57c5ba793fb74b8e9fdceb31bf158842","8fb73c16a2fc4649b05102a63b148df0"]}},"source":["# 분류를 위한 BERT 모델 생성\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n","# GPU가 있다면 다음의 cuda함수를 불러서 사용한다\n","model.cuda()"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1228988c5d1c4974b3721d90f3861918","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75f32edbca2c48788c69b836c64c2353","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"RlszxDr6h8GP"},"source":["![대체 텍스트](http://www.mccormickml.com/assets/BERT/padding_and_mask.png)\n","\n","사전훈련된 BERT는 다양한 문제로 전이학습이 가능합니다. 여기서는 위의 그림과 같이 한 문장을 분류하는 방법을 사용합니다. 영화리뷰 문장이 입력으로 들어가면, 긍정/부정으로 구분합니다. 모델의 출력에서 [CLS] 위치인 첫 번째 토큰에 새로운 레이어를 붙여서 파인튜닝을 합니다. Hugging Face는 BertForSequenceClassification() 함수를 제공하기 때문에 쉽게 구현할 수 있습니다.\n","<br>\n","<br>\n","<br>"]},{"cell_type":"code","metadata":{"id":"ZIdfbLTuWmxk","executionInfo":{"status":"ok","timestamp":1603944215580,"user_tz":-540,"elapsed":241547,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 옵티마이저 설정\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # 학습률\n","                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                )\n","\n","# 에폭수: CPU이면 에폭은 최소화한다\n","epochs = 5\n","\n","# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","total_steps = len(train_dataloader) * epochs\n","\n","# 학습률을 조금씩 감소시키는 스케줄러 생성\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gzCHV_ghj7DM"},"source":["<br>\n","\n","# **모델 학습**"]},{"cell_type":"code","metadata":{"id":"S0-p6pPVXCRe","executionInfo":{"status":"ok","timestamp":1603944215580,"user_tz":-540,"elapsed":241545,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    \n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"FJXISnJzCdLM","executionInfo":{"status":"ok","timestamp":1603944215581,"user_tz":-540,"elapsed":241544,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"muU2kS2GCh4y","outputId":"c45dd8c8-2191-4440-82c1-85ca3bec31c1","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","model.to(device)\n","\n","# 그래디언트 초기화\n","model.zero_grad()\n","\n","# 에폭만큼 반복\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # 훈련모드로 변경\n","    model.train()\n","        \n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        # 경과 정보 표시\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Forward 수행                \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","        \n","        # 로스 구함\n","        loss = outputs[0]\n","\n","        # 총 로스 계산\n","        total_loss += loss.item()\n","\n","        # Backward 수행으로 그래디언트 계산\n","        loss.backward()\n","\n","        # 그래디언트 클리핑\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\n","        optimizer.step()\n","\n","        # 스케줄러로 학습률 감소\n","        scheduler.step()\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    torch.save(model.state_dict(), path+'bert-model.pt')\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    #시작 시간 설정\n","    t0 = time.time()\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in validation_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # 그래디언트 계산 안함\n","        with torch.no_grad():     \n","            # Forward 수행\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # 로스 구함\n","        logits = outputs[0]\n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 5 ========\n","Training...\n","  Batch   500  of  4,219.    Elapsed: 0:05:49.\n","  Batch 1,000  of  4,219.    Elapsed: 0:11:42.\n","  Batch 1,500  of  4,219.    Elapsed: 0:17:35.\n","  Batch 2,000  of  4,219.    Elapsed: 0:23:28.\n","  Batch 2,500  of  4,219.    Elapsed: 0:29:22.\n","  Batch 3,000  of  4,219.    Elapsed: 0:35:15.\n","  Batch 3,500  of  4,219.    Elapsed: 0:41:08.\n","  Batch 4,000  of  4,219.    Elapsed: 0:47:01.\n","\n","  Average training loss: 0.39\n","  Training epcoh took: 0:49:38\n","\n","Running Validation...\n","  Accuracy: 0.85\n","  Validation took: 0:01:54\n","\n","======== Epoch 2 / 5 ========\n","Training...\n","  Batch   500  of  4,219.    Elapsed: 0:05:53.\n","  Batch 1,000  of  4,219.    Elapsed: 0:11:46.\n","  Batch 1,500  of  4,219.    Elapsed: 0:17:39.\n","  Batch 2,000  of  4,219.    Elapsed: 0:23:32.\n","  Batch 2,500  of  4,219.    Elapsed: 0:29:25.\n","  Batch 3,000  of  4,219.    Elapsed: 0:35:18.\n","  Batch 3,500  of  4,219.    Elapsed: 0:41:11.\n","  Batch 4,000  of  4,219.    Elapsed: 0:47:04.\n","\n","  Average training loss: 0.29\n","  Training epcoh took: 0:49:42\n","\n","Running Validation...\n","  Accuracy: 0.87\n","  Validation took: 0:01:54\n","\n","======== Epoch 3 / 5 ========\n","Training...\n","  Batch   500  of  4,219.    Elapsed: 0:05:53.\n","  Batch 1,000  of  4,219.    Elapsed: 0:11:46.\n","  Batch 1,500  of  4,219.    Elapsed: 0:17:39.\n","  Batch 2,000  of  4,219.    Elapsed: 0:23:33.\n","  Batch 2,500  of  4,219.    Elapsed: 0:29:26.\n","  Batch 3,000  of  4,219.    Elapsed: 0:35:19.\n","  Batch 3,500  of  4,219.    Elapsed: 0:41:12.\n","  Batch 4,000  of  4,219.    Elapsed: 0:47:06.\n","\n","  Average training loss: 0.23\n","  Training epcoh took: 0:49:43\n","\n","Running Validation...\n","  Accuracy: 0.87\n","  Validation took: 0:01:54\n","\n","======== Epoch 4 / 5 ========\n","Training...\n","  Batch   500  of  4,219.    Elapsed: 0:05:53.\n","  Batch 1,000  of  4,219.    Elapsed: 0:11:47.\n","  Batch 1,500  of  4,219.    Elapsed: 0:17:40.\n","  Batch 2,000  of  4,219.    Elapsed: 0:23:33.\n","  Batch 2,500  of  4,219.    Elapsed: 0:29:26.\n","  Batch 3,000  of  4,219.    Elapsed: 0:35:20.\n","  Batch 3,500  of  4,219.    Elapsed: 0:41:13.\n","  Batch 4,000  of  4,219.    Elapsed: 0:47:06.\n","\n","  Average training loss: 0.18\n","  Training epcoh took: 0:49:44\n","\n","Running Validation...\n","  Accuracy: 0.87\n","  Validation took: 0:01:54\n","\n","======== Epoch 5 / 5 ========\n","Training...\n","  Batch   500  of  4,219.    Elapsed: 0:05:53.\n","  Batch 1,000  of  4,219.    Elapsed: 0:11:47.\n","  Batch 1,500  of  4,219.    Elapsed: 0:17:40.\n","  Batch 2,000  of  4,219.    Elapsed: 0:23:33.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hxlXEBA0WefL"},"source":["에폭마다 훈련셋과 검증셋을 반복하여 학습을 수행합니다. "]},{"cell_type":"markdown","metadata":{"id":"6BVbl4Zjatzn"},"source":["<br>\n","<br>\n","\n","# **테스트셋 평가**"]},{"cell_type":"code","metadata":{"id":"c5KHb6RkbHdj"},"source":["#시작 시간 설정\n","t0 = time.time()\n","\n","# 평가모드로 변경\n","model.eval()\n","\n","# 변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","    # 경과 정보 표시\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # 배치에서 데이터 추출\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    # 출력 로짓과 라벨을 비교하여 정확도 계산\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DbsNMA8Idc3K"},"source":["한글 코퍼스로 pre-training하여 만든 모델과 우리는 BERT의 기본 모델인 bert-base-multilingual-cased를 사용했을 때 차이를 이해할 수 있어야 합니다."]},{"cell_type":"markdown","metadata":{"id":"U7SzL1IBe1Dm"},"source":["<br>\n","\n","# **새로운 문장 테스트**"]},{"cell_type":"code","metadata":{"id":"Tb4v_VfEfGQB"},"source":["# 입력 데이터 변환\n","def convert_input_data(sentences):\n","\n","    # BERT의 토크나이저로 문장을 토큰으로 분리\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    # 입력 토큰의 최대 시퀀스 길이\n","    MAX_LEN = 128\n","\n","    # 토큰을 숫자 인덱스로 변환\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","    \n","    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    # 어텐션 마스크 초기화\n","    attention_masks = []\n","\n","    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # 데이터를 파이토치의 텐서로 변환\n","    inputs = torch.tensor(input_ids)\n","    masks = torch.tensor(attention_masks)\n","\n","    return inputs, masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C12NL1Fvgv4E"},"source":["# 문장 테스트\n","def test_sentences(sentences):\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 문장을 입력 데이터로 변환\n","    inputs, masks = convert_input_data(sentences)\n","\n","    # 데이터를 GPU에 넣음\n","    b_input_ids = inputs.to(device)\n","    b_input_mask = masks.to(device)\n","            \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","\n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQezr0tljJlM"},"source":["logits = test_sentences(['연기는 별로지만 재미 하나는 끝내줌!'])\n","\n","print(logits)\n","print(np.argmax(logits))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9MQ0SK0jofN"},"source":["logits = test_sentences(['주연배우가 아깝다. 총체적 난국...'])\n","\n","print(logits)\n","print(np.argmax(logits))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H5mANMwKkA0D"},"source":["학습한 모델을 가지고 실제 문장을 넣어봤습니다. 출력 로짓은 소프트맥스가 적용되지 않은 상태입니다. argmax로 더 높은 값의 위치를 라벨로 설정하면 됩니다. 0은 부정, 1은 긍정입니다. 위와 같이 새로운 문장에도 잘 분류를 하고 있습니다.\n","<br>\n","<br>"]}]}