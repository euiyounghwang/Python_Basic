{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sentiment Classification Exercise.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1hHpSAEVqb-0FoKweKJnHQTpc_seETALS","authorship_tag":"ABX9TyN9tIhdCSaEr/DLYKmT9+fF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2d4nszaVMfwo"},"source":["- 저장된 RNN, CNN, BERT 모델을 load 합니다.\n","- nsmc/ratings_test.txt 파일을 읽고, 해당 파일 중 문장 길이가 5이상인 문장에 대해서 모델별 prediction을 진행합니다. \n","- 실제 label과 비교해서 어떤 모델이 가장 좋은 성능을 나타내는지 classification report(scikit-learn 참고)를 출력합니다."]},{"cell_type":"code","metadata":{"id":"rVSYpTdlxGjp","executionInfo":{"status":"ok","timestamp":1603949238225,"user_tz":-540,"elapsed":900,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["path = '/content/drive/My Drive/Colab Notebooks/2020-PoscoICT/Data/'"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PdoAGmP5w1au"},"source":["## BERT"]},{"cell_type":"code","metadata":{"id":"FNSJwCAowx4f","executionInfo":{"status":"ok","timestamp":1603949240887,"user_tz":-540,"elapsed":3556,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"fcc30098-b7af-4e43-abbc-2945bedbcfc4","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n","Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JsIwXK91Meqq","executionInfo":{"status":"ok","timestamp":1603949242912,"user_tz":-540,"elapsed":5576,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["import torch\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"moqxIPktwlBJ","executionInfo":{"status":"ok","timestamp":1603949249190,"user_tz":-540,"elapsed":11849,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"e3268c04-4368-4636-b3a5-fd9c0f7b3449","colab":{"base_uri":"https://localhost:8080/"}},"source":["bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"L9KyDxWNw52u","executionInfo":{"status":"ok","timestamp":1603949255194,"user_tz":-540,"elapsed":17848,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"b1d03504-5f7f-484b-ef15-1ee1b5d8cec5","colab":{"base_uri":"https://localhost:8080/"}},"source":["bert_model.load_state_dict(torch.load(path+'bert-model.pt'))"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"T4IdsjciyqgY","executionInfo":{"status":"ok","timestamp":1603949255194,"user_tz":-540,"elapsed":17842,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# BERT의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"zqNoA5d8yQ96","executionInfo":{"status":"ok","timestamp":1603949269864,"user_tz":-540,"elapsed":32508,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["import pandas as pd\n","import numpy as np\n","from keras.preprocessing.sequence import pad_sequences\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","test = pd.read_csv(path+\"nsmc/ratings_test.txt\", sep='\\t')\n","test.dropna(how='any', inplace=True)\n","\n","sentences = test['document']\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","labels = test['label'].values\n","# BERT의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 128\n","# 토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","# 어텐션 마스크 초기화\n","attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","# 데이터를 파이토치의 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","test_labels = torch.tensor(labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=8)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"cluvu3mE0PJd","executionInfo":{"status":"ok","timestamp":1603949269865,"user_tz":-540,"elapsed":32505,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    \n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"-5GzptKH0utv","executionInfo":{"status":"ok","timestamp":1603949269866,"user_tz":-540,"elapsed":32504,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":["# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"L_wK9AS1xFNI","executionInfo":{"status":"ok","timestamp":1603949712781,"user_tz":-540,"elapsed":412823,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}},"outputId":"e00f04eb-567c-4f8b-a20c-f99b3c8b057a","colab":{"base_uri":"https://localhost:8080/"}},"source":["import time\n","import datetime\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","#시작 시간 설정\n","t0 = time.time()\n","bert_model.to(device)\n","# 평가모드로 변경\n","bert_model.eval()\n","\n","# 변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","    # 경과 정보 표시\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # 배치에서 데이터 추출\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = bert_model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    # 출력 로짓과 라벨을 비교하여 정확도 계산\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["  Batch   100  of  6,250.    Elapsed: 0:00:06.\n","  Batch   200  of  6,250.    Elapsed: 0:00:12.\n","  Batch   300  of  6,250.    Elapsed: 0:00:18.\n","  Batch   400  of  6,250.    Elapsed: 0:00:24.\n","  Batch   500  of  6,250.    Elapsed: 0:00:31.\n","  Batch   600  of  6,250.    Elapsed: 0:00:37.\n","  Batch   700  of  6,250.    Elapsed: 0:00:43.\n","  Batch   800  of  6,250.    Elapsed: 0:00:50.\n","  Batch   900  of  6,250.    Elapsed: 0:00:56.\n","  Batch 1,000  of  6,250.    Elapsed: 0:01:03.\n","  Batch 1,100  of  6,250.    Elapsed: 0:01:10.\n","  Batch 1,200  of  6,250.    Elapsed: 0:01:17.\n","  Batch 1,300  of  6,250.    Elapsed: 0:01:24.\n","  Batch 1,400  of  6,250.    Elapsed: 0:01:30.\n","  Batch 1,500  of  6,250.    Elapsed: 0:01:37.\n","  Batch 1,600  of  6,250.    Elapsed: 0:01:43.\n","  Batch 1,700  of  6,250.    Elapsed: 0:01:50.\n","  Batch 1,800  of  6,250.    Elapsed: 0:01:57.\n","  Batch 1,900  of  6,250.    Elapsed: 0:02:03.\n","  Batch 2,000  of  6,250.    Elapsed: 0:02:10.\n","  Batch 2,100  of  6,250.    Elapsed: 0:02:16.\n","  Batch 2,200  of  6,250.    Elapsed: 0:02:23.\n","  Batch 2,300  of  6,250.    Elapsed: 0:02:30.\n","  Batch 2,400  of  6,250.    Elapsed: 0:02:36.\n","  Batch 2,500  of  6,250.    Elapsed: 0:02:43.\n","  Batch 2,600  of  6,250.    Elapsed: 0:02:50.\n","  Batch 2,700  of  6,250.    Elapsed: 0:02:56.\n","  Batch 2,800  of  6,250.    Elapsed: 0:03:03.\n","  Batch 2,900  of  6,250.    Elapsed: 0:03:10.\n","  Batch 3,000  of  6,250.    Elapsed: 0:03:16.\n","  Batch 3,100  of  6,250.    Elapsed: 0:03:23.\n","  Batch 3,200  of  6,250.    Elapsed: 0:03:29.\n","  Batch 3,300  of  6,250.    Elapsed: 0:03:36.\n","  Batch 3,400  of  6,250.    Elapsed: 0:03:43.\n","  Batch 3,500  of  6,250.    Elapsed: 0:03:49.\n","  Batch 3,600  of  6,250.    Elapsed: 0:03:56.\n","  Batch 3,700  of  6,250.    Elapsed: 0:04:03.\n","  Batch 3,800  of  6,250.    Elapsed: 0:04:09.\n","  Batch 3,900  of  6,250.    Elapsed: 0:04:16.\n","  Batch 4,000  of  6,250.    Elapsed: 0:04:23.\n","  Batch 4,100  of  6,250.    Elapsed: 0:04:29.\n","  Batch 4,200  of  6,250.    Elapsed: 0:04:36.\n","  Batch 4,300  of  6,250.    Elapsed: 0:04:43.\n","  Batch 4,400  of  6,250.    Elapsed: 0:04:49.\n","  Batch 4,500  of  6,250.    Elapsed: 0:04:56.\n","  Batch 4,600  of  6,250.    Elapsed: 0:05:03.\n","  Batch 4,700  of  6,250.    Elapsed: 0:05:09.\n","  Batch 4,800  of  6,250.    Elapsed: 0:05:16.\n","  Batch 4,900  of  6,250.    Elapsed: 0:05:23.\n","  Batch 5,000  of  6,250.    Elapsed: 0:05:29.\n","  Batch 5,100  of  6,250.    Elapsed: 0:05:36.\n","  Batch 5,200  of  6,250.    Elapsed: 0:05:43.\n","  Batch 5,300  of  6,250.    Elapsed: 0:05:49.\n","  Batch 5,400  of  6,250.    Elapsed: 0:05:56.\n","  Batch 5,500  of  6,250.    Elapsed: 0:06:02.\n","  Batch 5,600  of  6,250.    Elapsed: 0:06:09.\n","  Batch 5,700  of  6,250.    Elapsed: 0:06:16.\n","  Batch 5,800  of  6,250.    Elapsed: 0:06:22.\n","  Batch 5,900  of  6,250.    Elapsed: 0:06:29.\n","  Batch 6,000  of  6,250.    Elapsed: 0:06:36.\n","  Batch 6,100  of  6,250.    Elapsed: 0:06:42.\n","  Batch 6,200  of  6,250.    Elapsed: 0:06:49.\n","\n","Accuracy: 0.85\n","Test took: 0:06:52\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pCJs0XZVyIY8","executionInfo":{"status":"aborted","timestamp":1603949276371,"user_tz":-540,"elapsed":39000,"user":{"displayName":"Jaewon Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdj1-rEJRFWqZuVAXriUPzN3hAjW9XNSALxRZr=s64","userId":"03369539031933860370"}}},"source":[""],"execution_count":null,"outputs":[]}]}